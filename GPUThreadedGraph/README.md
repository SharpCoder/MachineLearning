MachineLearning
===============

This project was created in order to test a theory of mine regarding GPU processing. The idea was to deploy a many-to-many node tree (graph) into a GPU such that each GPU thread (of which there can be many) represented a single node in the graph. Evaluating the graph would be as simple as having each node poll the parent nodes simultaneously, do whatever mathematical calculation they wanted, and then update their own value. This idea was awesome enough, however, it turned out to have too much overhead to be effective. The interesting aspect of my algorithm was the potential for nearly infinite scalability. As a larger graph breadth was developed, the complexity of evaluation was supposed to remain fairly constant. This did turn out to be the case, which was awesome. But still, my calculations implied about 300 ticks of the CPU were utilized for a single evaluation. This may seem quick, but I got better performance using a CPU-based method. Still, my code may be useful to someone - so I'm leaving it up.